{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pravallikai/DocuMind_RAG-Implementation-/blob/main/DocuMindFINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QBOBA57SMnTq",
        "outputId": "115f7ba1-8e45-4898-9977-98069663cdb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Installing Gradio...\n",
            "Collecting gradio==4.12.0\n",
            "  Downloading gradio-4.12.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==4.12.0)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (5.5.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (1.0.0)\n",
            "Collecting gradio-client==0.8.0 (from gradio==4.12.0)\n",
            "  Downloading gradio_client-0.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (0.36.0)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio==4.12.0)\n",
            "  Downloading MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (3.10.0)\n",
            "Collecting numpy~=1.0 (from gradio==4.12.0)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (2.2.2)\n",
            "Collecting pillow<11.0,>=8.0 (from gradio==4.12.0)\n",
            "  Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (6.0.3)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (2.10.0)\n",
            "Collecting tomlkit==0.12.0 (from gradio==4.12.0)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.9 in /usr/local/lib/python3.12/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.12.0) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.12.0) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==0.8.0->gradio==4.12.0) (2025.3.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.8.0->gradio==4.12.0)\n",
            "  Downloading websockets-11.0.3-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair<6.0,>=4.2.0->gradio==4.12.0) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair<6.0,>=4.2.0->gradio==4.12.0) (2.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.3->gradio==4.12.0) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.3->gradio==4.12.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.3->gradio==4.12.0) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.3->gradio==4.12.0) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==4.12.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==4.12.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==4.12.0) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==4.12.0) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==4.12.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio==4.12.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio==4.12.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio==4.12.0) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->gradio==4.12.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->gradio==4.12.0) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->gradio==4.12.0) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.12.0) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.12.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.12.0) (13.9.4)\n",
            "\u001b[33mWARNING: typer 0.20.0 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.14.0->gradio==4.12.0) (0.16.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi->gradio==4.12.0) (0.48.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->gradio==4.12.0) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->gradio==4.12.0) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->gradio==4.12.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->gradio==4.12.0) (3.11)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.12.0) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.12.0) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.12.0) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.12.0) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.12.0) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.12.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.12.0) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.19.3->gradio==4.12.0) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.19.3->gradio==4.12.0) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.12.0) (0.1.2)\n",
            "Downloading gradio-4.12.0-py3-none-any.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.8.0-py3-none-any.whl (305 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m305.1/305.1 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, tomlkit, pillow, numpy, markupsafe, aiofiles, gradio-client, gradio\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.3\n",
            "    Uninstalling tomlkit-0.13.3:\n",
            "      Successfully uninstalled tomlkit-0.13.3\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.3\n",
            "    Uninstalling MarkupSafe-3.0.3:\n",
            "      Successfully uninstalled MarkupSafe-3.0.3\n",
            "  Attempting uninstall: aiofiles\n",
            "    Found existing installation: aiofiles 24.1.0\n",
            "    Uninstalling aiofiles-24.1.0:\n",
            "      Successfully uninstalled aiofiles-24.1.0\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.14.0\n",
            "    Uninstalling gradio_client-1.14.0:\n",
            "      Successfully uninstalled gradio_client-1.14.0\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.50.0\n",
            "    Uninstalling gradio-5.50.0:\n",
            "      Successfully uninstalled gradio-5.50.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "dataproc-spark-connect 1.0.1 requires websockets>=14.0, but you have websockets 11.0.3 which is incompatible.\n",
            "google-adk 1.20.0 requires websockets<16.0.0,>=15.0.1, but you have websockets 11.0.3 which is incompatible.\n",
            "google-genai 1.54.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\n",
            "yfinance 0.2.66 requires websockets>=13.0, but you have websockets 11.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 gradio-4.12.0 gradio-client-0.8.0 markupsafe-2.1.5 numpy-1.26.4 pillow-10.4.0 tomlkit-0.12.0 websockets-11.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "numpy"
                ]
              },
              "id": "cb8aa6181f4949f28ab1cb40ad8e2928"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîß Installing sentence-transformers...\n",
            "Collecting sentence-transformers==3.0.0\n",
            "  Downloading sentence_transformers-3.0.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.0) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.0) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.0) (2.9.0+cpu)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.0) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.0) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.0) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.0) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.0) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.0) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.0) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.0) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.0) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==3.0.0) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.0) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.0) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.0) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.0) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==3.0.0) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==3.0.0) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers==3.0.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==3.0.0) (2.1.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==3.0.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==3.0.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==3.0.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==3.0.0) (2025.11.12)\n",
            "Downloading sentence_transformers-3.0.0-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence-transformers\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 5.1.2\n",
            "    Uninstalling sentence-transformers-5.1.2:\n",
            "      Successfully uninstalled sentence-transformers-5.1.2\n",
            "Successfully installed sentence-transformers-3.0.0\n",
            "\n",
            "üîß Installing FAISS...\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.1\n",
            "\n",
            "üîß Installing PyPDF2...\n",
            "Collecting PyPDF2==3.0.1\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "\n",
            "üîß Installing python-docx...\n",
            "Collecting python-docx==1.1.0\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx==1.1.0) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from python-docx==1.1.0) (4.15.0)\n",
            "Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.0\n",
            "\n",
            "üîß Installing OpenAI...\n",
            "Collecting openai==1.6.1\n",
            "  Downloading openai-1.6.1-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.6.1) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.6.1) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.6.1) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.6.1) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai==1.6.1) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai==1.6.1) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.12/dist-packages (from openai==1.6.1) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai==1.6.1) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==1.6.1) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==1.6.1) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.6.1) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.6.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.6.1) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.6.1) (0.4.2)\n",
            "Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.9.0\n",
            "    Uninstalling openai-2.9.0:\n",
            "      Successfully uninstalled openai-2.9.0\n",
            "Successfully installed openai-1.6.1\n",
            "\n",
            "==================================================\n",
            "‚úÖ ALL PACKAGES INSTALLED SUCCESSFULLY!\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "#Install all dependencies\n",
        "\n",
        "print(\"üîß Installing Gradio...\") # Show a message that Gradio is being installed.\n",
        "!pip install gradio==4.12.0 # Install Gradio, which helps create easy-to-use web apps, making sure it's version 4.12.0.\n",
        "\n",
        "print(\"\\nüîß Installing sentence-transformers...\") # Show a message that sentence-transformers is being installed.\n",
        "!pip install sentence-transformers==3.0.0 # Install sentence-transformers, which turns words into numbers, making sure it's version 3.0.0.\n",
        "\n",
        "print(\"\\nüîß Installing FAISS...\") # Show a message that FAISS is being installed.\n",
        "!pip install faiss-cpu # Install FAISS, which helps find similar number patterns very quickly.\n",
        "\n",
        "print(\"\\nüîß Installing PyPDF2...\") # Show a message that PyPDF2 is being installed.\n",
        "!pip install PyPDF2==3.0.1 # Install PyPDF2, which helps read and understand PDF files, making sure it's version 3.0.1.\n",
        "\n",
        "print(\"\\nüîß Installing python-docx...\") # Show a message that python-docx is being installed.\n",
        "!pip install python-docx==1.1.0 # Install python-docx, which helps read and understand Word document files, making sure it's version 1.1.0.\n",
        "\n",
        "print(\"\\nüîß Installing OpenAI...\") # Show a message that OpenAI library is being installed.\n",
        "!pip install openai==1.6.1 # Install the OpenAI library, which helps talk to powerful AI models, making sure it's version 1.6.1.\n",
        "\n",
        "print(\"\\n\" + \"=\"*50) # Print a new line and a line of 50 '=' characters for a separator.\n",
        "print(\"‚úÖ ALL PACKAGES INSTALLED SUCCESSFULLY!\") # Show a success message that all necessary tools are ready.\n",
        "print(\"=\"*50) # Print another line of 50 '=' characters for a separator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77WiTfIBPsz1",
        "outputId": "f7caf207-a8ce-48f6-d8a6-c58ede764459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting openai\n",
            "  Downloading openai-2.13.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Downloading openai-2.13.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.6.1\n",
            "    Uninstalling openai-1.6.1:\n",
            "      Successfully uninstalled openai-1.6.1\n",
            "Successfully installed openai-2.13.0\n",
            "‚úÖ OpenAI upgraded!\n"
          ]
        }
      ],
      "source": [
        "#install dependency more...\n",
        "# This command tells the computer to install the 'openai' library or make sure it's the newest version.\n",
        "# The 'openai' library helps our program talk to smart AI models made by OpenAI.\n",
        "!pip install --upgrade openai\n",
        "\n",
        "# This line prints a message to the screen to let us know that the OpenAI tool has been updated successfully.\n",
        "print(\"‚úÖ OpenAI upgraded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1cwVAWkNyL4",
        "outputId": "f2de0961-5c87-42dd-baa2-452c3ba17f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ NVIDIA API key configured!\n"
          ]
        }
      ],
      "source": [
        "# Setup NVIDIA API key\n",
        "import os # This line brings in a special tool called 'os' which helps us do things like talk to the computer's system.\n",
        "\n",
        "# üî¥ PASTE YOUR NVIDIA API KEY BETWEEN THE QUOTES BELOW\n",
        "os.environ['NVIDIA_API_KEY'] = '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' # This line sets up a secret code (called an API key) so our program can use NVIDIA's smart AI tools. It's like a special password.\n",
        "\n",
        "print(\"‚úÖ NVIDIA API key configured!\") # This line tells us that the secret code for NVIDIA's tools has been set up successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZeWEurjN16v",
        "outputId": "87a31c4b-d7df-4089-d546-204b41d47b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ DocumentLoader created!\n"
          ]
        }
      ],
      "source": [
        "# document_loader.py - Loads PDF, DOCX, TXT files\n",
        "import PyPDF2 # This line brings in a special tool called 'PyPDF2' that helps us work with PDF files.\n",
        "from docx import Document # This line brings in another special tool called 'Document' from 'docx' that helps us work with Word document files.\n",
        "import io # This line brings in a tool called 'io' which helps us handle files like they are in memory, not just on the computer's hard drive.\n",
        "\n",
        "class DocumentLoader: # This is like creating a special helper robot named 'DocumentLoader' that knows how to get text from different kinds of files.\n",
        "    \"\"\"Loads text from PDF, DOCX, or TXT files\"\"\" # This tells us what our 'DocumentLoader' robot does: it loads text from PDF, DOCX, or TXT files.\n",
        "\n",
        "    def load(self, file_path, file_type): # This is like telling our robot, 'Hey, when you need to load a file, I'll give you its location (file_path) and what kind of file it is (file_type).'\n",
        "        \"\"\"\n",
        "        Loads a document and returns its text\n",
        "\n",
        "        file_path: path to the file\n",
        "        file_type: 'pdf', 'docx', or 'txt'\n",
        "        \"\"\" # These lines explain what the 'load' function does and what information it needs.\n",
        "        if file_type == 'pdf': # This line checks if the file is a PDF.\n",
        "            return self._load_pdf(file_path) # If it's a PDF, our robot uses its special PDF-reading skill.\n",
        "        elif file_type == 'docx': # This line checks if the file is a Word document.\n",
        "            return self._load_docx(file_path) # If it's a Word document, our robot uses its special Word-reading skill.\n",
        "        elif file_type == 'txt': # This line checks if the file is a simple text file.\n",
        "            return self._load_txt(file_path) # If it's a text file, our robot uses its special text-reading skill.\n",
        "        else: # If the file is not PDF, DOCX, or TXT, then...\n",
        "            raise ValueError(f\"Unsupported file type: {file_type}\") # ...our robot says, 'I don't know how to read this kind of file!' and stops.\n",
        "\n",
        "    def _load_pdf(self, file_path): # This is the robot's special skill for reading PDF files.\n",
        "        \"\"\"Extract text from PDF\"\"\" # This tells us this skill takes out text from a PDF.\n",
        "        text = \"\" # We start with an empty basket to collect all the text.\n",
        "        with open(file_path, 'rb') as file: # This line opens the PDF file very carefully so our robot can look inside it.\n",
        "            pdf_reader = PyPDF2.PdfReader(file) # Our robot uses the 'PyPDF2' tool to start reading the PDF.\n",
        "            for page in pdf_reader.pages: # Our robot goes through each page in the PDF, one by one.\n",
        "                text += page.extract_text() + \"\\n\" # Our robot takes all the words from each page and puts them in our basket, adding a new line after each page.\n",
        "        return text # Finally, our robot gives us all the text it collected in the basket.\n",
        "\n",
        "    def _load_docx(self, file_path): # This is the robot's special skill for reading Word document files.\n",
        "        \"\"\"Extract text from Word document\"\"\" # This tells us this skill takes out text from a Word document.\n",
        "        doc = Document(file_path) # Our robot uses the 'Document' tool to open the Word file.\n",
        "        text = \"\" # We start with an empty basket for the text.\n",
        "        for paragraph in doc.paragraphs: # Our robot looks at each paragraph in the Word document.\n",
        "            text += paragraph.text + \"\\n\" # Our robot takes all the words from each paragraph and puts them in our basket, adding a new line after each paragraph.\n",
        "        return text # Finally, our robot gives us all the text it collected.\n",
        "\n",
        "    def _load_txt(self, file_path): # This is the robot's special skill for reading simple text files.\n",
        "        \"\"\"Extract text from plain text file\"\"\" # This tells us this skill takes out text from a plain text file.\n",
        "        with open(file_path, 'r', encoding='utf-8') as file: # This line opens the text file so our robot can read it, making sure it understands different kinds of letters.\n",
        "            text = file.read() # Our robot reads everything in the text file and puts it into our basket.\n",
        "        return text # Finally, our robot gives us all the text it read.\n",
        "\n",
        "print(\"‚úÖ DocumentLoader created!\") # This line prints a happy message telling us our 'DocumentLoader' robot is ready to go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGofbBhkN8tf",
        "outputId": "91e42b40-f714-4eea-e170-ee515feeae51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ TextChunker created!\n"
          ]
        }
      ],
      "source": [
        "# chunker.py\n",
        "\n",
        "class TextChunker: # This is like a special machine named 'TextChunker' that helps cut big pieces of text into smaller ones.\n",
        "    \"\"\"Splits long text into smaller chunks for processing\"\"\" # This tells us what our 'TextChunker' machine does: it cuts long text into smaller pieces so it's easier to work with.\n",
        "\n",
        "    def __init__(self, chunk_size=500, overlap=50): # This is like setting up our machine, telling it how big each piece of text should be (chunk_size) and how much they should overlap (overlap).\n",
        "        \"\"\"\n",
        "        chunk_size: how many characters per chunk (like cutting a rope into pieces)\n",
        "        overlap: how many characters overlap between chunks (so we don't lose context)\n",
        "        \"\"\" # These lines explain what 'chunk_size' (how long each piece of text is) and 'overlap' (how much the pieces share) mean.\n",
        "        self.chunk_size = chunk_size # This line saves how big each piece of text should be.\n",
        "        self.overlap = overlap # This line saves how much the pieces of text should overlap.\n",
        "\n",
        "    def chunk(self, text): # This is the button we press to tell the machine to start cutting the text.\n",
        "        \"\"\"Split text into overlapping chunks\"\"\" # This tells us this button makes the machine cut the text into pieces that might share a little bit of words.\n",
        "        chunks = [] # We start with an empty basket to put all the small pieces of text.\n",
        "        start = 0 # This is like marking the beginning of where we are cutting in the big piece of text.\n",
        "\n",
        "        while start < len(text): # This is like saying, 'Keep cutting as long as there's still more text to cut.'\n",
        "            end = start + self.chunk_size # This marks where the current piece of text should end.\n",
        "            chunk = text[start:end] # This cuts out one small piece of text.\n",
        "\n",
        "            # Only add non-empty chunks\n",
        "            if chunk.strip(): # This checks if the piece of text is not empty or just spaces.\n",
        "                chunks.append(chunk.strip()) # If it's a real piece of text, we put it in our basket.\n",
        "\n",
        "            start += (self.chunk_size - self.overlap) # This moves our starting mark forward, but not all the way, so the next piece can share some words with this one.\n",
        "\n",
        "        return chunks # Finally, the machine gives us our basket full of small text pieces.\n",
        "\n",
        "print(\"‚úÖ TextChunker created!\") # This line prints a happy message telling us our 'TextChunker' machine is ready to go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "5BgphcypOBvn",
        "outputId": "316ce3a9-ecf3-48e5-e461-47c243d5e388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-805789288.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# embedder.py - Turns text into number codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m \u001b[0;31m# This line brings in a special tool called 'SentenceTransformer' that helps turn sentences into numbers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEmbedder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# This is like a special machine named 'Embedder' that turns words into secret number codes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEncoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallelSentencesDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentencesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoggingHandler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoggingHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/cross_encoder/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mCrossEncoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"CrossEncoder\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_torch_npu_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPushToHubMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/modeling_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m from .auto_factory import (\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0m_BaseAutoBackboneClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0m_BaseAutoModelClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_deepspeed_zero3_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_fsdp_managed_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasking_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_masks_for_generate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misin_mps_friendly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtensionsTrie\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/masking_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_torch_greater_or_equal_than_2_6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_wrapped_higher_order_op\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformGetItemToIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from . import (\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0maot_compile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/aot_compile.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecompile_context\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrecompileContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallbackTrigger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mObservedException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         )\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "# embedder.py - Turns text into number codes\n",
        "\n",
        "from sentence_transformers import SentenceTransformer # This line brings in a special tool called 'SentenceTransformer' that helps turn sentences into numbers.\n",
        "\n",
        "class Embedder: # This is like a special machine named 'Embedder' that turns words into secret number codes.\n",
        "    \"\"\"Converts text chunks into numerical vectors\"\"\" # This tells us what our 'Embedder' machine does: it changes pieces of text into lists of numbers.\n",
        "\n",
        "    def __init__(self, model_name='all-MiniLM-L6-v2'): # This is like setting up our machine, and we tell it which number-code language to use (like 'all-MiniLM-L6-v2').\n",
        "        \"\"\"\n",
        "        Loads a small, fast model that turns words into numbers\n",
        "        Think of it like translating English into a secret number language\n",
        "        \"\"\" # These lines explain that the machine loads a quick tool to change words into numbers, like a secret code translator.\n",
        "        print(\"Loading embedding model...\") # This line tells us that the machine is starting to load the number-code translator.\n",
        "        self.model = SentenceTransformer(model_name) # This line actually loads the number-code translator into our machine.\n",
        "        print(\"‚úÖ Embedding model loaded!\") # This line tells us the number-code translator is ready to go!\n",
        "\n",
        "    def embed(self, texts): # This is the button we press to tell the machine to turn a list of texts into number codes.\n",
        "        \"\"\"\n",
        "        Convert a list of text chunks into vectors\n",
        "\n",
        "        texts: list of strings\n",
        "        returns: list of numerical vectors\n",
        "        \"\"\" # These lines explain what the 'embed' function does and what kind of information it needs and gives back.\n",
        "        embeddings = self.model.encode(texts, show_progress_bar=True) # Our machine uses the translator to change the texts into number codes, and shows us a progress bar while it works.\n",
        "        return embeddings # Finally, the machine gives us back the list of number codes.\n",
        "\n",
        "print(\"‚úÖ Embedder created!\") # This line prints a happy message telling us our 'Embedder' machine is ready to go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iZKCFeqOnjW"
      },
      "outputs": [],
      "source": [
        "# vector_store.py - Stores and searches chunks\n",
        "\n",
        "import faiss # This line brings in a super-fast tool called 'faiss' that helps us find similar things very quickly.\n",
        "import numpy as np # This line brings in a tool called 'numpy' that helps us work with numbers in a special way, like big lists of them.\n",
        "\n",
        "class VectorStore: # This is like creating a special storage box named 'VectorStore' that holds our text pieces and helps us find them.\n",
        "    \"\"\"Stores document chunks and finds relevant ones quickly\"\"\" # This tells us what our 'VectorStore' box does: it keeps parts of documents and helps us find the right ones fast.\n",
        "\n",
        "    def __init__(self, dimension=384): # This is like setting up our storage box, telling it how much space each item needs (dimension).\n",
        "        \"\"\"\n",
        "        dimension: size of each vector (384 is standard for our embedding model)\n",
        "        Think of this as creating empty toy boxes to store our chunks\n",
        "        \"\"\" # These lines explain what 'dimension' means (how many numbers describe each piece of text) and compare it to empty toy boxes.\n",
        "        self.dimension = dimension # This line remembers how much space each item needs in our box.\n",
        "        self.index = faiss.IndexFlatL2(dimension) # This sets up the 'faiss' tool inside our box to help organize items for quick searching.\n",
        "        self.chunks = [] # This is like an empty shelf where we will put all the actual pieces of text.\n",
        "\n",
        "    def add(self, embeddings, chunks): # This is like putting new items into our storage box, both their secret number codes and the actual text pieces.\n",
        "        \"\"\"\n",
        "        Add chunks and their embeddings to the store\n",
        "\n",
        "        embeddings: numerical vectors\n",
        "        chunks: the actual text pieces\n",
        "        \"\"\" # These lines explain what 'embeddings' (number codes) and 'chunks' (text pieces) are.\n",
        "        embeddings = np.array(embeddings).astype('float32') # This line changes the number codes into a special format that 'faiss' can understand.\n",
        "        self.index.add(embeddings) # This adds the formatted number codes to our 'faiss' search tool.\n",
        "        self.chunks.extend(chunks) # This adds the actual text pieces to our shelf.\n",
        "        print(f\"‚úÖ Added {len(chunks)} chunks to vector store!\") # This line prints a message saying how many pieces of text were added to our storage box.\n",
        "\n",
        "    def search(self, query_embedding, top_k=3): # This is like asking our storage box a question (query_embedding) and asking it to find the best few answers (top_k).\n",
        "        \"\"\"\n",
        "        Find the most relevant chunks for a query\n",
        "\n",
        "        query_embedding: vector of the question\n",
        "        top_k: how many chunks to return (default 3)\n",
        "        \"\"\" # These lines explain what 'query_embedding' (question's number code) and 'top_k' (how many answers to get) mean.\n",
        "        query_embedding = np.array([query_embedding]).astype('float32') # This line changes our question's number code into the special format 'faiss' needs.\n",
        "        distances, indices = self.index.search(query_embedding, top_k) # This asks 'faiss' to find the closest number codes (and their locations) to our question.\n",
        "\n",
        "        results = [] # This is an empty basket where we will put the best text pieces found.\n",
        "        for idx in indices[0]: # This looks at the locations of the best matching number codes.\n",
        "            if idx < len(self.chunks): # This checks if the location is actually a valid spot on our shelf.\n",
        "                results.append(self.chunks[idx]) # If it's a valid spot, we take that text piece and put it in our basket.\n",
        "\n",
        "        return results # Finally, our storage box gives us the best text pieces from our basket.\n",
        "\n",
        "    def clear(self): # This is like pressing a reset button to empty our entire storage box.\n",
        "        \"\"\"Reset the vector store\"\"\" # This tells us this button makes the storage box forget everything.\n",
        "        self.index = faiss.IndexFlatL2(self.dimension) # This creates a brand new, empty 'faiss' search tool for our box.\n",
        "        self.chunks = [] # This clears off our shelf, making it empty again.\n",
        "        print(\"‚úÖ Vector store cleared!\") # This line prints a message saying our storage box is now empty and ready for new items.\n",
        "\n",
        "print(\"‚úÖ VectorStore created!\") # This line prints a happy message telling us our 'VectorStore' storage box is ready to go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5BBZJPuOo-e"
      },
      "outputs": [],
      "source": [
        "# nvidia_llm.py - Talks to NVIDIA's smart brain\n",
        "\n",
        "import os # This line brings in a special tool called 'os' which helps us do things like talk to the computer's system.\n",
        "from openai import OpenAI # This line brings in a special tool called 'OpenAI' that helps us talk to powerful AI models.\n",
        "\n",
        "class NvidiaLLM: # This is like creating a special helper robot named 'NvidiaLLM' that knows how to talk to NVIDIA's smart AI brain.\n",
        "    \"\"\"Communicates with NVIDIA's language model\"\"\" # This tells us what our 'NvidiaLLM' robot does: it talks to NVIDIA's AI model.\n",
        "\n",
        "    def __init__(self): # This is like setting up our robot for the first time.\n",
        "        \"\"\"Setup connection to NVIDIA API\"\"\" # This tells us this part connects our robot to NVIDIA's AI brain.\n",
        "        api_key = os.environ.get('NVIDIA_API_KEY') # Our robot looks for a secret code (API key) that lets it talk to NVIDIA's AI brain.\n",
        "        if not api_key: # If the robot can't find the secret code...\n",
        "            raise ValueError(\"NVIDIA_API_KEY not found! Did you run Cell 2?\") # ...it says, 'I can't find my secret code! Did you set it up?' and stops.\n",
        "\n",
        "        self.client = OpenAI(\n",
        "            base_url=\"https://integrate.api.nvidia.com/v1\", # This is like telling our robot the address of NVIDIA's AI brain.\n",
        "            api_key=api_key # This gives our robot the secret code to get into NVIDIA's AI brain.\n",
        "        ) # This line finishes setting up our robot to talk to NVIDIA's AI brain.\n",
        "        print(\"‚úÖ NVIDIA LLM connection established!\") # This line prints a happy message telling us our robot is connected to NVIDIA's AI brain.\n",
        "\n",
        "    def generate(self, prompt, max_tokens=1000): # This is the button we press to ask NVIDIA's AI brain a question (prompt) and tell it how long of an answer we want (max_tokens).\n",
        "        \"\"\"\n",
        "        Send a prompt to NVIDIA and get an answer\n",
        "\n",
        "        prompt: the question + document chunks\n",
        "        max_tokens: maximum length of answer\n",
        "        \"\"\" # These lines explain what the 'generate' function does and what information it needs and gives back.\n",
        "        try: # This is like saying, 'Try to do this, and if something goes wrong, I have a plan.'\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"meta/llama-3.1-8b-instruct\", # This tells NVIDIA's AI brain which specific smart brain to use for the answer.\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}], # This sends our question to the smart brain.\n",
        "                max_tokens=max_tokens, # This tells the smart brain not to write too long of an answer.\n",
        "                temperature=0.2 # This makes the smart brain's answer a little less random and more to the point.\n",
        "            ) # This line gets the answer back from NVIDIA's AI brain.\n",
        "            return response.choices[0].message.content # This gives us just the written answer from the smart brain.\n",
        "        except Exception as e: # If something went wrong while talking to the AI brain...\n",
        "            return f\"Error calling NVIDIA API: {str(e)}\" # ...our robot tells us there was a problem and what it was.\n",
        "\n",
        "print(\"‚úÖ NvidiaLLM created!\") # This line prints a happy message telling us our 'NvidiaLLM' robot is ready to go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNm5v9SDO8We"
      },
      "outputs": [],
      "source": [
        "# rag_pipeline.py - Connects everything together\n",
        "\n",
        "class RAGPipeline: # This is like the main brain of our project, named 'RAGPipeline', that makes sure all the other parts work together.\n",
        "    \"\"\"The main brain that coordinates all components\"\"\" # This tells us what the 'RAGPipeline' brain does: it brings all the different tools together.\n",
        "\n",
        "    def __init__(self): # This is like turning on our main brain for the first time and setting up all its helpers.\n",
        "        \"\"\"Initialize all components\"\"\" # This explains that this part gets all the tools ready to be used.\n",
        "        self.loader = DocumentLoader() # Our brain gets a 'DocumentLoader' robot to read files.\n",
        "        self.chunker = TextChunker(chunk_size=500, overlap=50) # Our brain gets a 'TextChunker' machine to cut text into pieces.\n",
        "        self.embedder = Embedder() # Our brain gets an 'Embedder' machine to turn words into number codes.\n",
        "        self.vector_store = VectorStore() # Our brain gets a 'VectorStore' box to store and find text pieces.\n",
        "        self.llm = NvidiaLLM() # Our brain gets an 'NvidiaLLM' robot to talk to NVIDIA's smart AI brain.\n",
        "        self.current_document = None # This is like our brain's clipboard, which is empty when we start.\n",
        "        print(\"‚úÖ RAG Pipeline ready!\") # This message tells us that our main brain and all its helpers are ready to work!\n",
        "\n",
        "    def process_document(self, file_path, file_type): # This is like giving our main brain a new document to read, telling it where the file is (file_path) and what kind of file it is (file_type).\n",
        "        \"\"\"\n",
        "        Process an uploaded document\n",
        "\n",
        "        Steps:\n",
        "        1. Load the document\n",
        "        2. Split into chunks\n",
        "        3. Create embeddings\n",
        "        4. Store in vector database\n",
        "        \"\"\" # These lines explain the steps our brain takes to handle a new document.\n",
        "        # Load document\n",
        "        text = self.loader.load(file_path, file_type) # Our brain tells the 'DocumentLoader' robot to read the document and gives it the words.\n",
        "        self.current_document = text # Our brain saves the document's words on its clipboard.\n",
        "\n",
        "        # Chunk text\n",
        "        chunks = self.chunker.chunk(text) # Our brain tells the 'TextChunker' machine to cut the words into smaller pieces.\n",
        "\n",
        "        # Create embeddings\n",
        "        embeddings = self.embedder.embed(chunks) # Our brain tells the 'Embedder' machine to turn these text pieces into secret number codes.\n",
        "\n",
        "        # Clear old data and add new\n",
        "        self.vector_store.clear() # Our brain tells the 'VectorStore' box to empty itself first.\n",
        "        self.vector_store.add(embeddings, chunks) # Then, our brain tells the 'VectorStore' box to store the new number codes and text pieces.\n",
        "\n",
        "        return f\"‚úÖ Document processed! Created {len(chunks)} chunks.\" # Our brain tells us it's done processing the document and how many pieces it made.\n",
        "\n",
        "    def answer_question(self, question): # This is like asking our main brain a question (question) after it has read a document.\n",
        "        \"\"\"\n",
        "        Answer a question based on the document\n",
        "\n",
        "        Steps:\n",
        "        1. Convert question to embedding\n",
        "        2. Find relevant chunks\n",
        "        3. Send chunks + question to LLM\n",
        "        4. Return answer + sources\n",
        "        \"\"\" # These lines explain the steps our brain takes to answer a question.\n",
        "        if not self.current_document: # This checks if our brain has a document on its clipboard.\n",
        "            return \"‚ùå Please upload a document first!\", [] # If there's no document, our brain says it needs one first.\n",
        "\n",
        "        # Get question embedding\n",
        "        question_embedding = self.embedder.embed([question])[0] # Our brain tells the 'Embedder' machine to turn our question into a secret number code.\n",
        "\n",
        "        # Find relevant chunks\n",
        "        relevant_chunks = self.vector_store.search(question_embedding, top_k=3) # Our brain tells the 'VectorStore' box to find the best text pieces related to our question.\n",
        "\n",
        "        if not relevant_chunks: # This checks if the 'VectorStore' box found any related text pieces.\n",
        "            return \"‚ùå No relevant information found in the document.\", [] # If not, our brain says it couldn't find an answer in the document.\n",
        "\n",
        "        # Create prompt for LLM\n",
        "        context = \"\\n\\n\".join([f\"[Chunk {i+1}]: {chunk}\" for i, chunk in enumerate(relevant_chunks)]) # Our brain gathers the related text pieces to help the smart AI.\n",
        "        prompt = f\"\"\"You are a document analysis assistant. Answer the question based ONLY on the provided document chunks. If the answer is not in the chunks, say \"I don't know based on the uploaded document.\"\n",
        "\n",
        "Document Chunks:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\" # Our brain creates a special message for the smart AI, including the question and the helpful text pieces.\n",
        "\n",
        "        # Get answer from LLM\n",
        "        answer = self.llm.generate(prompt) # Our brain sends the special message to the 'NvidiaLLM' robot to get an answer from the smart AI.\n",
        "\n",
        "        return answer, relevant_chunks # Our brain gives us the answer from the smart AI and the text pieces it used.\n",
        "\n",
        "    def summarize(self): # This is like asking our main brain to tell us the main idea of the document.\n",
        "        \"\"\"Generate a summary of the entire document\"\"\" # This tells us this part makes a short version of the document.\n",
        "        if not self.current_document: # This checks if our brain has a document on its clipboard.\n",
        "            return \"‚ùå Please upload a document first!\" # If there's no document, our brain says it needs one first.\n",
        "\n",
        "        # Take first 3000 characters for summary\n",
        "        text_sample = self.current_document[:3000] # Our brain takes the first 3000 letters of the document to make a summary.\n",
        "\n",
        "        prompt = f\"\"\"Summarize the following document in 3-5 clear sentences:\n",
        "\n",
        "{text_sample}\n",
        "\n",
        "Summary:\"\"\" # Our brain creates a special message for the smart AI, asking it to summarize the text.\n",
        "\n",
        "        summary = self.llm.generate(prompt, max_tokens=300) # Our brain sends the message to the 'NvidiaLLM' robot to get a summary from the smart AI, keeping it short.\n",
        "        return summary # Our brain gives us the summary.\n",
        "\n",
        "    def extract_topics(self): # This is like asking our main brain to find the main ideas in the document.\n",
        "        \"\"\"Extract key topics from the document\"\"\" # This tells us this part finds the most important subjects in the document.\n",
        "        if not self.current_document: # This checks if our brain has a document on its clipboard.\n",
        "            return \"‚ùå Please upload a document first!\" # If there's no document, our brain says it needs one first.\n",
        "\n",
        "        # Take first 3000 characters\n",
        "        text_sample = self.current_document[:3000] # Our brain takes the first 3000 letters of the document to find the main ideas.\n",
        "\n",
        "        prompt = f\"\"\"Extract the 5-7 main topics or themes from this document. List them as bullet points:\n",
        "\n",
        "{text_sample}\n",
        "\n",
        "Main Topics:\"\"\" # Our brain creates a special message for the smart AI, asking it to list the main topics.\n",
        "\n",
        "        topics = self.llm.generate(prompt, max_tokens=300) # Our brain sends the message to the 'NvidiaLLM' robot to get the main topics from the smart AI, keeping the list short.\n",
        "        return topics # Our brain gives us the list of main topics.\n",
        "\n",
        "print(\"‚úÖ RAGPipeline created!\") # This message tells us that our main brain 'RAGPipeline' is all set up!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1TN14JhPLa-"
      },
      "outputs": [],
      "source": [
        "# app.py - The visual interface\n",
        "\n",
        "import gradio as gr # This line brings in a special tool called 'gradio' that helps us make a simple website for our AI tool.\n",
        "import shutil # This line brings in a tool called 'shutil' that helps us do things with computer files, like copying them.\n",
        "import os # This line brings in a special tool called 'os' which helps us do things like talk to the computer's system.\n",
        "\n",
        "# Create RAG pipeline\n",
        "pipeline = RAGPipeline() # This line starts our main brain, the 'RAGPipeline', getting it ready to do its job.\n",
        "\n",
        "def upload_document(file): # This is like a special instruction for our website: 'When someone uploads a document, here's what to do with it.'\n",
        "    \"\"\"Handle document upload\"\"\" # This tells us what the 'upload_document' instruction is for.\n",
        "    if file is None: # This checks if a file was actually uploaded.\n",
        "        return \"‚ùå Please select a file!\" # If no file was uploaded, it tells the user to pick one.\n",
        "\n",
        "    # Determine file type\n",
        "    file_ext = file.name.split('.')[-1].lower() # This line figures out what kind of file it is (like 'pdf', 'docx', or 'txt').\n",
        "    if file_ext == 'pdf': # This checks if the file is a PDF.\n",
        "        file_type = 'pdf' # If it is, we remember it's a PDF.\n",
        "    elif file_ext == 'docx': # This checks if the file is a Word document.\n",
        "        file_type = 'docx' # If it is, we remember it's a DOCX.\n",
        "    elif file_ext == 'txt': # This checks if the file is a plain text file.\n",
        "        file_type = 'txt' # If it is, we remember it's a TXT.\n",
        "    else: # If the file is none of those...\n",
        "        return f\"‚ùå Unsupported file type: {file_ext}\" # ...it tells the user it doesn't know how to handle that kind of file.\n",
        "\n",
        "    # Process document\n",
        "    result = pipeline.process_document(file.name, file_type) # This line tells our main brain to start working on the uploaded document.\n",
        "    return result # This sends back a message about how the document was processed.\n",
        "\n",
        "def ask_question(question): # This is like another special instruction for our website: 'When someone asks a question, here's what to do.'\n",
        "    \"\"\"Handle question answering\"\"\" # This tells us what the 'ask_question' instruction is for.\n",
        "    if not question.strip(): # This checks if the user actually typed a question.\n",
        "        return \"‚ùå Please enter a question!\", \"\" # If not, it tells them to type a question.\n",
        "\n",
        "    answer, chunks = pipeline.answer_question(question) # This line tells our main brain to answer the question and also gives us the pieces of information it used.\n",
        "\n",
        "    # Format source chunks\n",
        "    sources = \"\\n\\n\".join([f\"üìÑ Source Chunk {i+1}:\\n{chunk[:300]}...\" for i, chunk in enumerate(chunks)]) # This makes the source information look nice and tidy for the user.\n",
        "\n",
        "    return answer, sources # This gives back the answer and the pieces of information it came from.\n",
        "\n",
        "def summarize_doc(): # This is like an instruction for our website: 'When someone asks for a summary, here's what to do.'\n",
        "    \"\"\"Handle summarization\"\"\" # This tells us what the 'summarize_doc' instruction is for.\n",
        "    summary = pipeline.summarize() # This line tells our main brain to make a summary of the document.\n",
        "    return summary # This gives back the summary.\n",
        "\n",
        "def extract_topics_doc(): # This is like an instruction for our website: 'When someone asks for topics, here's what to do.'\n",
        "    \"\"\"Handle topic extraction\"\"\" # This tells us what the 'extract_topics_doc' instruction is for.\n",
        "    topics = pipeline.extract_topics() # This line tells our main brain to find the main topics in the document.\n",
        "    return topics # This gives back the list of topics.\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks(title=\"DocuMind - AI Research Assistant\") as app: # This line starts building the website itself, giving it a name.\n",
        "    gr.Markdown(\"# üß† DocuMind: AI-Powered Document Assistant\") # This adds a big title to the website.\n",
        "    gr.Markdown(\"Upload a PDF, DOCX, or TXT file and ask questions about it!\") # This adds a small instruction text to the website.\n",
        "\n",
        "    with gr.Tab(\"üì§ Upload Document\"): # This creates a section on the website called 'Upload Document'.\n",
        "        file_input = gr.File(label=\"Upload your document (PDF, DOCX, or TXT)\") # This adds a button for people to upload their files.\n",
        "        upload_btn = gr.Button(\"Process Document\", variant=\"primary\") # This adds a button that says 'Process Document'.\n",
        "        upload_output = gr.Textbox(label=\"Status\", lines=3) # This adds a box to show messages about the upload status.\n",
        "\n",
        "        upload_btn.click( # This makes the 'Process Document' button do something when clicked.\n",
        "            fn=upload_document, # When clicked, it runs our 'upload_document' instruction.\n",
        "            inputs=file_input, # It uses the file from the 'file_input' button.\n",
        "            outputs=upload_output # It shows the messages in the 'upload_output' box.\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"üí¨ Ask Questions\"): # This creates another section on the website called 'Ask Questions'.\n",
        "        question_input = gr.Textbox(label=\"Your Question\", placeholder=\"What is this document about?\") # This adds a box for people to type their questions.\n",
        "        ask_btn = gr.Button(\"Get Answer\", variant=\"primary\") # This adds a button that says 'Get Answer'.\n",
        "        answer_output = gr.Textbox(label=\"Answer\", lines=5) # This adds a box to show the answer to the question.\n",
        "        sources_output = gr.Textbox(label=\"Source Chunks\", lines=8) # This adds a box to show where the answer came from.\n",
        "\n",
        "        ask_btn.click( # This makes the 'Get Answer' button do something when clicked.\n",
        "            fn=ask_question, # When clicked, it runs our 'ask_question' instruction.\n",
        "            inputs=question_input, # It uses the question typed in the 'question_input' box.\n",
        "            outputs=[answer_output, sources_output] # It shows the answer and sources in their respective boxes.\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"üìù Summarize\"): # This creates another section on the website called 'Summarize'.\n",
        "        summarize_btn = gr.Button(\"Generate Summary\", variant=\"primary\") # This adds a button that says 'Generate Summary'.\n",
        "        summary_output = gr.Textbox(label=\"Summary\", lines=6) # This adds a box to show the summary.\n",
        "\n",
        "        summarize_btn.click( # This makes the 'Generate Summary' button do something when clicked.\n",
        "            fn=summarize_doc, # When clicked, it runs our 'summarize_doc' instruction.\n",
        "            inputs=None, # It doesn't need any special input from the user.\n",
        "            outputs=summary_output # It shows the summary in the 'summary_output' box.\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"üè∑Ô∏è Extract Topics\"): # This creates another section on the website called 'Extract Topics'.\n",
        "        topics_btn = gr.Button(\"Extract Key Topics\", variant=\"primary\") # This adds a button that says 'Extract Key Topics'.\n",
        "        topics_output = gr.Textbox(label=\"Main Topics\", lines=6) # This adds a box to show the main topics.\n",
        "\n",
        "        topics_btn.click( # This makes the 'Extract Key Topics' button do something when clicked.\n",
        "            fn=extract_topics_doc, # When clicked, it runs our 'extract_topics_doc' instruction.\n",
        "            inputs=None, # It doesn't need any special input from the user.\n",
        "            outputs=topics_output # It shows the topics in the 'topics_output' box.\n",
        "        )\n",
        "\n",
        "print(\"‚úÖ Gradio UI created!\") # This line prints a happy message telling us our website is ready to be shown!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErhPU3owQuDU"
      },
      "outputs": [],
      "source": [
        "# Launch DocuMind!\n",
        "\n",
        "app.launch(share=False, debug=True) # This line starts our website so people can use it. The 'share=False' means only you can see it, and 'debug=True' helps us find any boo-boos while it's running."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# üì¶ DOWNLOAD ENTIRE NOTEBOOK AS ZIP\n",
        "# ================================\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from IPython.display import FileLink\n",
        "\n",
        "# Name of the zip file\n",
        "ZIP_NAME = \"DocuMindFINAL.zip\"\n",
        "\n",
        "# Get current working directory\n",
        "BASE_DIR = os.getcwd()\n",
        "\n",
        "print(f\"üìÇ Zipping contents of: {BASE_DIR}\")\n",
        "\n",
        "# Create ZIP file\n",
        "with zipfile.ZipFile(ZIP_NAME, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for foldername, subfolders, filenames in os.walk(BASE_DIR):\n",
        "        for filename in filenames:\n",
        "            file_path = os.path.join(foldername, filename)\n",
        "\n",
        "            # Avoid zipping the zip itself\n",
        "            if filename != ZIP_NAME:\n",
        "                arcname = os.path.relpath(file_path, BASE_DIR)\n",
        "                zipf.write(file_path, arcname)\n",
        "\n",
        "print(\"‚úÖ ZIP file created successfully!\")\n",
        "\n",
        "# Provide download link\n",
        "FileLink(ZIP_NAME)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "BLYHaiIZU58D",
        "outputId": "57cd5a65-f073-4887-ae87-32d4126c37e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Zipping contents of: /content\n",
            "‚úÖ ZIP file created successfully!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/content/DocuMindFINAL.zip"
            ],
            "text/html": [
              "<a href='DocuMindFINAL.zip' target='_blank'>DocuMindFINAL.zip</a><br>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHGm8skLShc0PMpJbiRSAc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}